{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "class ConLLUParser:\n",
    "\n",
    "    def __init__(self, path, verbose=False) -> None:\n",
    "        # open .conllu file and split each line and remove the '\\n' character at the end\n",
    "        with open(path) as f:\n",
    "            raw_lines = f.read().splitlines()\n",
    "            #splitting lines from the conlu parser \n",
    "        \n",
    "        # retrieve the name of the columns\n",
    "        self.col_names = [\n",
    "            'ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC'\n",
    "        ]\n",
    "        \n",
    "        # all_words stores each word of the corpus, identified by sent_id (id of the sentence in the corpus) and the ID (position of the word in the sentence)\n",
    "        # all_contractions stores the contractions, e.g. 'du' -> 'de le' ; 'didn't' -> 'did n't'\n",
    "        # all_sentences stores each sentence of the corpus, identified by sent_id and computes the length of the sentence\n",
    "        all_words, all_contractions, all_sentences = [], [], []\n",
    "        \n",
    "        # temporary variables\n",
    "        temp, count, n_exceptions = [], 0, 0\n",
    "\n",
    "        # treat the corpus line by line using pop function\n",
    "        while len(raw_lines) > 0:\n",
    "            \n",
    "            line = raw_lines.pop(0)\n",
    "            if len(line) > 0:\n",
    "                splits = line.split('\\t')\n",
    "            \n",
    "            # the sentences always start by a line giving the sent_id \"# sent_id = ...\"\n",
    "            if line.startswith('# sent_id = '):\n",
    "                id = line.replace('# sent_id = ', '')\n",
    "                temp.append(id)\n",
    "                \n",
    "            \n",
    "            # then another one gives the sentence \"# text = ...\"\n",
    "            elif line.startswith('# text = '):\n",
    "                text = line.replace('# text = ', '')\n",
    "                temp.append(text)\n",
    "            \n",
    "            # a sentence is ended by a blank line\n",
    "            elif line == '':\n",
    "                if count > 0:\n",
    "                    temp.append(count)\n",
    "                    all_sentences.append(temp)\n",
    "                count = 0\n",
    "                temp = []\n",
    "\n",
    "            # print all lines that don't start by a digit as their are not useful\n",
    "            # count them for later sanity checks\n",
    "            elif not line[0].isdigit():\n",
    "                if verbose:\n",
    "                    print(f'IS OMITTED: {line}')\n",
    "                n_exceptions += 1\n",
    "\n",
    "            # the lines that start by a number contain the words and their characteristics\n",
    "            elif splits[0].isdigit():\n",
    "                assert len(splits) == len(self.col_names)\n",
    "                all_words.append([id] + splits)\n",
    "                count += 1\n",
    "\n",
    "            # if the start of a line contains a dash, then it represents a contradiction\n",
    "            elif '-' in splits[0] or '.' in splits[0]:\n",
    "                all_contractions.append([id] + splits[:2])\n",
    "            \n",
    "            else:\n",
    "                raise ValueError(f'Cannot handle this line: {line}')\n",
    "            \n",
    "\n",
    "        self.sentences = pd.DataFrame(all_sentences, columns=['sent_id', 'text', 'length'])\n",
    "        self.words = pd.DataFrame(all_words, columns=['sent_id'] + self.col_names)\n",
    "        self.contradictions = pd.DataFrame(all_contractions, columns=['sent_id', 'ID', 'FORM'])\n",
    "            \n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    verbose = False\n",
    "    fr_train = ConLLUParser('fr_gsd-ud-train.conllu', verbose)\n",
    "    fr_dev = ConLLUParser('fr_gsd-ud-dev.conllu', verbose)\n",
    "    fr_test = ConLLUParser('fr_gsd-ud-test.conllu', verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contradictions=fr_train.contradictions\n",
    "train_sentences=fr_train.sentences\n",
    "train_words=fr_train.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>Les commotions cérébrales sont devenu si coura...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr-ud-train_00002</td>\n",
       "      <td>L'œuvre est située dans la galerie des bataill...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr-ud-train_00003</td>\n",
       "      <td>Le comportement de la Turquie vis-à-vis du pro...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr-ud-train_00004</td>\n",
       "      <td>Toutefois, les filles adorent les desserts.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr-ud-train_00005</td>\n",
       "      <td>Ismene entre et annonce que c'est Farnace qui ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14445</th>\n",
       "      <td>fr-ud-train_14550</td>\n",
       "      <td>Le 28 mars 1792, ces territoires formèrent deu...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14446</th>\n",
       "      <td>fr-ud-train_14551</td>\n",
       "      <td>Ce débutant de l'année 1983 et double All-Star...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14447</th>\n",
       "      <td>fr-ud-train_14552</td>\n",
       "      <td>La population est alors indigène et fait parti...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14448</th>\n",
       "      <td>fr-ud-train_14553</td>\n",
       "      <td>Mais MSI propose aussi, pour 699 euros, une ve...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14449</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>Selon une première hypothèse, l'origine est is...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14450 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sent_id                                               text  \\\n",
       "0      fr-ud-train_00001  Les commotions cérébrales sont devenu si coura...   \n",
       "1      fr-ud-train_00002  L'œuvre est située dans la galerie des bataill...   \n",
       "2      fr-ud-train_00003  Le comportement de la Turquie vis-à-vis du pro...   \n",
       "3      fr-ud-train_00004        Toutefois, les filles adorent les desserts.   \n",
       "4      fr-ud-train_00005  Ismene entre et annonce que c'est Farnace qui ...   \n",
       "...                  ...                                                ...   \n",
       "14445  fr-ud-train_14550  Le 28 mars 1792, ces territoires formèrent deu...   \n",
       "14446  fr-ud-train_14551  Ce débutant de l'année 1983 et double All-Star...   \n",
       "14447  fr-ud-train_14552  La population est alors indigène et fait parti...   \n",
       "14448  fr-ud-train_14553  Mais MSI propose aussi, pour 699 euros, une ve...   \n",
       "14449  fr-ud-train_14554  Selon une première hypothèse, l'origine est is...   \n",
       "\n",
       "       length  \n",
       "0          19  \n",
       "1          17  \n",
       "2          34  \n",
       "3           8  \n",
       "4          18  \n",
       "...       ...  \n",
       "14445      22  \n",
       "14446      58  \n",
       "14447      25  \n",
       "14448      25  \n",
       "14449      43  \n",
       "\n",
       "[14450 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>FORM</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>UPOS</th>\n",
       "      <th>XPOS</th>\n",
       "      <th>FEATS</th>\n",
       "      <th>HEAD</th>\n",
       "      <th>DEPREL</th>\n",
       "      <th>DEPS</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>Les</td>\n",
       "      <td>le</td>\n",
       "      <td>DET</td>\n",
       "      <td>_</td>\n",
       "      <td>Definite=Def|Number=Plur|PronType=Art</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>_</td>\n",
       "      <td>wordform=les</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>2</td>\n",
       "      <td>commotions</td>\n",
       "      <td>commotion</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Fem|Number=Plur</td>\n",
       "      <td>5</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>3</td>\n",
       "      <td>cérébrales</td>\n",
       "      <td>cérébral</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Fem|Number=Plur</td>\n",
       "      <td>2</td>\n",
       "      <td>amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>4</td>\n",
       "      <td>sont</td>\n",
       "      <td>être</td>\n",
       "      <td>AUX</td>\n",
       "      <td>_</td>\n",
       "      <td>Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>5</td>\n",
       "      <td>aux:tense</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>5</td>\n",
       "      <td>devenu</td>\n",
       "      <td>devenir</td>\n",
       "      <td>VERB</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Masc|Number=Sing|Tense=Past|Typo=Yes|Ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>_</td>\n",
       "      <td>CorrectForm=devenues|CorrectGender=Fem|Correct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354562</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>39</td>\n",
       "      <td>d'</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>40</td>\n",
       "      <td>case</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354563</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>40</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>ADP</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>38</td>\n",
       "      <td>advmod</td>\n",
       "      <td>_</td>\n",
       "      <td>ExtPos=ADV|Idiom=Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354564</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>41</td>\n",
       "      <td>haut</td>\n",
       "      <td>haut</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Masc|Number=Sing</td>\n",
       "      <td>40</td>\n",
       "      <td>fixed</td>\n",
       "      <td>_</td>\n",
       "      <td>InIdiom=Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354565</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>42</td>\n",
       "      <td>»</td>\n",
       "      <td>»</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>34</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354566</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>43</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>9</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354567 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sent_id  ID        FORM      LEMMA   UPOS XPOS  \\\n",
       "0       fr-ud-train_00001   1         Les         le    DET    _   \n",
       "1       fr-ud-train_00001   2  commotions  commotion   NOUN    _   \n",
       "2       fr-ud-train_00001   3  cérébrales   cérébral    ADJ    _   \n",
       "3       fr-ud-train_00001   4        sont       être    AUX    _   \n",
       "4       fr-ud-train_00001   5      devenu    devenir   VERB    _   \n",
       "...                   ...  ..         ...        ...    ...  ...   \n",
       "354562  fr-ud-train_14554  39          d'         de    ADP    _   \n",
       "354563  fr-ud-train_14554  40          en         en    ADP    _   \n",
       "354564  fr-ud-train_14554  41        haut       haut   NOUN    _   \n",
       "354565  fr-ud-train_14554  42           »          »  PUNCT    _   \n",
       "354566  fr-ud-train_14554  43           .          .  PUNCT    _   \n",
       "\n",
       "                                                    FEATS HEAD     DEPREL  \\\n",
       "0                   Definite=Def|Number=Plur|PronType=Art    2        det   \n",
       "1                                  Gender=Fem|Number=Plur    5      nsubj   \n",
       "2                                  Gender=Fem|Number=Plur    2       amod   \n",
       "3       Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbF...    5  aux:tense   \n",
       "4       Gender=Masc|Number=Sing|Tense=Past|Typo=Yes|Ve...    0       root   \n",
       "...                                                   ...  ...        ...   \n",
       "354562                                                  _   40       case   \n",
       "354563                                                  _   38     advmod   \n",
       "354564                            Gender=Masc|Number=Sing   40      fixed   \n",
       "354565                                                  _   34      punct   \n",
       "354566                                                  _    9      punct   \n",
       "\n",
       "       DEPS                                               MISC  \n",
       "0         _                                       wordform=les  \n",
       "1         _                                                  _  \n",
       "2         _                                                  _  \n",
       "3         _                                                  _  \n",
       "4         _  CorrectForm=devenues|CorrectGender=Fem|Correct...  \n",
       "...     ...                                                ...  \n",
       "354562    _                                      SpaceAfter=No  \n",
       "354563    _                               ExtPos=ADV|Idiom=Yes  \n",
       "354564    _                                        InIdiom=Yes  \n",
       "354565    _                                      SpaceAfter=No  \n",
       "354566    _                                                  _  \n",
       "\n",
       "[354567 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_train.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN     66421\n",
       "ADP      56473\n",
       "DET      54144\n",
       "PUNCT    39011\n",
       "VERB     28185\n",
       "PROPN    24750\n",
       "ADJ      20981\n",
       "PRON     16050\n",
       "ADV      12443\n",
       "AUX      11587\n",
       "CCONJ     9301\n",
       "NUM       9255\n",
       "X         2680\n",
       "SCONJ     2598\n",
       "SYM        619\n",
       "INTJ        69\n",
       "Name: UPOS, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_interest=train_words[['FORM','UPOS']]\n",
    "words_interest.groupby('UPOS')\n",
    "words_interest['UPOS'].value_counts(normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "POS_LABEL = [\n",
    "    \"NOUN\", \"ADP\", \"DET\", \"PUNCT\", \"VERB\", \"PROPN\", \"ADJ\", \"PRON\", \"ADV\",\n",
    "    \"AUX\", \"CCONJ\", \"NUM\", \"X\", \"SCONJ\", \"SYM\", \"INTJ\"\n",
    "]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NaiveClassifier:\n",
    "    \n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "\n",
    "        assert 'FORM' in data.columns, 'Column FORM is missing from data'\n",
    "        \n",
    "        def naive_rules(word):\n",
    "            word = word.lower()  # Convert word to lowercase for consistent rule checking\n",
    "            \n",
    "            if word.endswith(('tion', 'sion', 'ment')) or word in ['ville', 'année', 'pays', 'nom', 'jour', 'mois', 'homme', 'femme', 'vie', 'enfant']:\n",
    "                return 'NOUN'\n",
    "            \n",
    "            if word.endswith(('er', 'ir', 're')) or word in ['être', 'avoir', 'est', 'était', 'été', 'fut', 'étant']:\n",
    "                return 'VERB'\n",
    "            if word in ['être', 'avoir', 'est', 'était', 'été', 'fut', 'étant']:\n",
    "                return 'AUX'\n",
    "            if word.endswith(('eux', 'euse')) or word in ['premier', 'première', 'français', 'française', 'nouveau', 'nouvelle', 'grand', 'grande', 'petit', 'petite']:\n",
    "                return 'ADJ'\n",
    "            if word.endswith('ment') or word in ['très', 'bien', 'aussi', 'toujours', 'surtout', 'encore', 'trop', 'jamais', 'vraiment']:\n",
    "                return 'ADV'\n",
    "            if word in ['le', 'la', 'les', 'l', 'un', 'une', 'des']:\n",
    "                return 'DET'\n",
    "            if word in ['il', 'elle', 'nous', 'vous', 'ils', 'elles', 'lui', 'on', 'je', 'me', 'ma', 'mon', 'leur', 'leurs']:\n",
    "                return 'PRON'\n",
    "            if word in ['et', 'ou', 'mais', 'donc']:\n",
    "                return 'CCONJ'\n",
    "            if word in ['que', 'quand', 'si', 'lorsque']:\n",
    "                return 'SCONJ'\n",
    "            if word in ['de', 'à', 'en', 'sur', 'avec', 'dans', 'par', 'pour', 'sans', 'sous', 'contre', 'après', 'avant', 'vers', 'chez']:\n",
    "                return 'ADP'\n",
    "            if word.isdigit() or word in ['un', 'deux', 'trois', 'deuxième', 'troisième']:\n",
    "                return 'NUM'\n",
    "            if word[0].isupper() and word not in ['et', 'ou', 'mais', 'donc']:\n",
    "                return 'PROPN'\n",
    "            if word in [',', '.', '(', ')', ':', ';', '«', '»', '!', '?']:\n",
    "                return 'PUNCT'\n",
    "            if word in ['%', '€']:\n",
    "                return 'SYM'\n",
    "            if word in ['oh', 'ah', 'eh']:\n",
    "                return 'INTJ'\n",
    "            return 'NOUN'\n",
    "\n",
    "        \n",
    "        return data.FORM.apply(naive_rules).tolist()\n",
    "    def evaluate(self, y_true, y_pred):\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "class RandomClassifier:\n",
    "\n",
    "    def __init__(self, random_seed=0) -> None:\n",
    "        self.random_seed = random_seed\n",
    "        self.label = POS_LABEL\n",
    "    \n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        random.seed(self.random_seed)\n",
    "        return [random.choice(self.label) for _ in range(len(data))]\n",
    "    def evaluate(self, y_true, y_pred):\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "class StratifiedClassifier: \n",
    "    def __init__(self) -> None :\n",
    "        pass\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        valuecounts= data['UPOS'].value_counts(normalize=True).to_dict()\n",
    "        probabilities = list(valuecounts.values())\n",
    "        labels = list(valuecounts.keys())\n",
    "        N=len(data)\n",
    "        \n",
    "        return np.random.choice(POS_LABEL, size=N, p=probabilities)\n",
    "    def evaluate(self, data: pd.DataFrame):\n",
    "        y_true = data['UPOS'].tolist()\n",
    "        y_pred = self.predict(data)\n",
    "        \n",
    "        assert len(y_true) == len(y_pred), \"y_true and y_pred do not have the same length\"\n",
    "        \n",
    "        metrics = {}\n",
    "        metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "        return metrics\n",
    "\n",
    "class MostCommonPOSClassifier:\n",
    "    def __init__(self) -> None:\n",
    "        self.most_common_pos = None\n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        self.most_common_pos = data['UPOS'].value_counts().idxmax()    \n",
    "        return [self.most_common_pos] * len(data)\n",
    "    \n",
    "    def evaluate(self, data: pd.DataFrame):\n",
    "        y_true = data['UPOS'].tolist()\n",
    "        y_pred = self.predict(data)\n",
    "        assert len(y_true) == len(y_pred), \"y_true and y_pred do not have the same length\"\n",
    "        metrics = {}\n",
    "        metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "        return metrics\n",
    "\n",
    "class WordDistributedRandomClassifier:\n",
    "    def __init__(self):\n",
    "        self.word_distributions = {}\n",
    "        self.global_distribution = None\n",
    "\n",
    "    def fit(self, data: pd.DataFrame):\n",
    "        #on train_data\n",
    "        # what's the POS distribution on each word \n",
    "        self.global_distribution = data['UPOS'].value_counts(normalize=True).to_dict()\n",
    "        for word, group in data.groupby('FORM'):\n",
    "            self.word_distributions[word] = group['UPOS'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        predictions = []\n",
    "        for word in data['FORM']:\n",
    "            if word in self.word_distributions:\n",
    "                pos_tags = list(self.word_distributions[word].keys())\n",
    "                probabilities = list(self.word_distributions[word].values())\n",
    "                predictions.append(np.random.choice(pos_tags, p=probabilities))\n",
    "            else:\n",
    "                pos_tags = list(self.global_distribution.keys())\n",
    "                probabilities = list(self.global_distribution.values())\n",
    "                predictions.append(np.random.choice(pos_tags, p=probabilities))\n",
    "        return predictions\n",
    "\n",
    "    def evaluate(self, data: pd.DataFrame):\n",
    "        y_true = data['UPOS'].tolist()\n",
    "        y_pred = self.predict(data)\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "data = train_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_distributed_classifier = WordDistributedRandomClassifier()\n",
    "word_distributed_classifier.fit(train_words)  # Assuming train_data is your training dataset\n",
    "# Training and evaluating\n",
    "word_distributed_classifier = WordDistributedRandomClassifier()\n",
    "word_distributed_classifier.fit(train_data)  # Assuming train_data is your training dataset\n",
    "\n",
    "predictions = word_distributed_classifier.predict(test_data)  # Assuming test_data is your test dataset\n",
    "\n",
    "accuracy = evaluate(test_data['UPOS'].tolist(), predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveClassifier: {'accuracy': 0.11635882639952393}\n"
     ]
    }
   ],
   "source": [
    "stratifiedClassifier = StratifiedClassifier()\n",
    "stratified_accuracy = stratifiedClassifier.evaluate(data)\n",
    "print(f\"Accuracy of StratifiedClassifier: {stratified_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUX', 'NOUN', 'PROPN', ..., 'DET', 'DET', 'NOUN'], dtype='<U5')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratified_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurence_of_words=data['FORM'].value_counts()\n",
    "occurence_of_words.to_csv('occurence_of_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveClassifier: 0.6216004309481706\n",
      "Accuracy of RandomClassifier with seed 0: {'accuracy': 0.06279490195083016}\n",
      "Accuracy of RandomClassifier with seed 1: {'accuracy': 0.06276669853652483}\n",
      "Accuracy of RandomClassifier with seed 2: {'accuracy': 0.06123807348117563}\n",
      "Accuracy of RandomClassifier with seed 3: {'accuracy': 0.062453640637735605}\n",
      "Accuracy of RandomClassifier with seed 4: {'accuracy': 0.06364382472142077}\n",
      "Accuracy of RandomClassifier with seed 5: {'accuracy': 0.062287240493334124}\n",
      "Accuracy of RandomClassifier with seed 6: {'accuracy': 0.06234082698051426}\n",
      "Accuracy of RandomClassifier with seed 7: {'accuracy': 0.06260311873355388}\n",
      "Accuracy of RandomClassifier with seed 8: {'accuracy': 0.06235492868766693}\n",
      "Accuracy of RandomClassifier with seed 9: {'accuracy': 0.061759836645824344}\n",
      "Accuracy of StratifiedClassifier: {'accuracy': 0.11656189098252234}\n",
      "Accuracy of MostCommonClassifier: {'accuracy': 0.18732989815747095}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#Q1: ____________________________\n",
    "naive_classifier = NaiveClassifier()\n",
    "random_classifier = RandomClassifier()\n",
    "\n",
    "naive_predictions = naive_classifier.predict(data)\n",
    "\n",
    "naive_accuracy = naive_classifier.evaluate(data['UPOS'].tolist(), naive_predictions)\n",
    "print(f\"Accuracy of NaiveClassifier: {naive_accuracy}\")\n",
    "\n",
    "#Q2: For 10 differentt seeds, computing accuracy per each case : \n",
    "for seed in range(10):\n",
    "    random_classifier = RandomClassifier(random_seed=seed)\n",
    "    random_predictions = random_classifier.predict(data)\n",
    "    random_accuracy = evaluate(data['UPOS'].tolist(), random_predictions)\n",
    "    print(f\"Accuracy of RandomClassifier with seed {seed}: {random_accuracy}\")\n",
    "    \n",
    "# Q3: For POS distribution : \n",
    "stratifiedClassifier = StratifiedClassifier()\n",
    "stratified_accuracy = stratifiedClassifier.evaluate(data)\n",
    "print(f\"Accuracy of StratifiedClassifier: {stratified_accuracy}\")\n",
    "\n",
    "# Q4: For mostCommon POS: \n",
    "mostCommonPOSClassifier = MostCommonPOSClassifier()\n",
    "mostCommonPOSClassifier_accuracy = mostCommonPOSClassifier.evaluate(data)\n",
    "print(f\"Accuracy of MostCommonClassifier: {mostCommonPOSClassifier_accuracy}\")\n",
    "\n",
    "# Q5: \n",
    "word_distributed_classifier = WordDistributedClassifier()\n",
    "word_distributed_classifier.fit(train_data)  # Assuming train_data is your training dataset\n",
    "\n",
    "predictions = word_distributed_classifier.predict(test_data)  # Assuming test_data is your test dataset\n",
    "\n",
    "accuracy = evaluate(test_data['UPOS'].tolist(), predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : by frequency of each POS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " answer has been detailed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN     0.187330\n",
       "ADP      0.159273\n",
       "DET      0.152705\n",
       "PUNCT    0.110024\n",
       "VERB     0.079491\n",
       "PROPN    0.069803\n",
       "ADJ      0.059174\n",
       "PRON     0.045266\n",
       "ADV      0.035094\n",
       "AUX      0.032679\n",
       "CCONJ    0.026232\n",
       "NUM      0.026102\n",
       "X        0.007559\n",
       "SCONJ    0.007327\n",
       "SYM      0.001746\n",
       "INTJ     0.000195\n",
       "Name: UPOS, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=data.UPOS.value_counts(normalize=True)\n",
    "c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:  random for each POS that doesn't belong to training data words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>ID</th>\n",
       "      <th>FORM</th>\n",
       "      <th>LEMMA</th>\n",
       "      <th>UPOS</th>\n",
       "      <th>XPOS</th>\n",
       "      <th>FEATS</th>\n",
       "      <th>HEAD</th>\n",
       "      <th>DEPREL</th>\n",
       "      <th>DEPS</th>\n",
       "      <th>MISC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>1</td>\n",
       "      <td>Les</td>\n",
       "      <td>le</td>\n",
       "      <td>DET</td>\n",
       "      <td>_</td>\n",
       "      <td>Definite=Def|Number=Plur|PronType=Art</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>_</td>\n",
       "      <td>wordform=les</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>2</td>\n",
       "      <td>commotions</td>\n",
       "      <td>commotion</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Fem|Number=Plur</td>\n",
       "      <td>5</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>3</td>\n",
       "      <td>cérébrales</td>\n",
       "      <td>cérébral</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Fem|Number=Plur</td>\n",
       "      <td>2</td>\n",
       "      <td>amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>4</td>\n",
       "      <td>sont</td>\n",
       "      <td>être</td>\n",
       "      <td>AUX</td>\n",
       "      <td>_</td>\n",
       "      <td>Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>5</td>\n",
       "      <td>aux:tense</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fr-ud-train_00001</td>\n",
       "      <td>5</td>\n",
       "      <td>devenu</td>\n",
       "      <td>devenir</td>\n",
       "      <td>VERB</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Masc|Number=Sing|Tense=Past|Typo=Yes|Ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>_</td>\n",
       "      <td>CorrectForm=devenues|CorrectGender=Fem|Correct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354562</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>39</td>\n",
       "      <td>d'</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>40</td>\n",
       "      <td>case</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354563</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>40</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>ADP</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>38</td>\n",
       "      <td>advmod</td>\n",
       "      <td>_</td>\n",
       "      <td>ExtPos=ADV|Idiom=Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354564</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>41</td>\n",
       "      <td>haut</td>\n",
       "      <td>haut</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>_</td>\n",
       "      <td>Gender=Masc|Number=Sing</td>\n",
       "      <td>40</td>\n",
       "      <td>fixed</td>\n",
       "      <td>_</td>\n",
       "      <td>InIdiom=Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354565</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>42</td>\n",
       "      <td>»</td>\n",
       "      <td>»</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>34</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354566</th>\n",
       "      <td>fr-ud-train_14554</td>\n",
       "      <td>43</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>9</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354567 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sent_id  ID        FORM      LEMMA   UPOS XPOS  \\\n",
       "0       fr-ud-train_00001   1         Les         le    DET    _   \n",
       "1       fr-ud-train_00001   2  commotions  commotion   NOUN    _   \n",
       "2       fr-ud-train_00001   3  cérébrales   cérébral    ADJ    _   \n",
       "3       fr-ud-train_00001   4        sont       être    AUX    _   \n",
       "4       fr-ud-train_00001   5      devenu    devenir   VERB    _   \n",
       "...                   ...  ..         ...        ...    ...  ...   \n",
       "354562  fr-ud-train_14554  39          d'         de    ADP    _   \n",
       "354563  fr-ud-train_14554  40          en         en    ADP    _   \n",
       "354564  fr-ud-train_14554  41        haut       haut   NOUN    _   \n",
       "354565  fr-ud-train_14554  42           »          »  PUNCT    _   \n",
       "354566  fr-ud-train_14554  43           .          .  PUNCT    _   \n",
       "\n",
       "                                                    FEATS HEAD     DEPREL  \\\n",
       "0                   Definite=Def|Number=Plur|PronType=Art    2        det   \n",
       "1                                  Gender=Fem|Number=Plur    5      nsubj   \n",
       "2                                  Gender=Fem|Number=Plur    2       amod   \n",
       "3       Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbF...    5  aux:tense   \n",
       "4       Gender=Masc|Number=Sing|Tense=Past|Typo=Yes|Ve...    0       root   \n",
       "...                                                   ...  ...        ...   \n",
       "354562                                                  _   40       case   \n",
       "354563                                                  _   38     advmod   \n",
       "354564                            Gender=Masc|Number=Sing   40      fixed   \n",
       "354565                                                  _   34      punct   \n",
       "354566                                                  _    9      punct   \n",
       "\n",
       "       DEPS                                               MISC  \n",
       "0         _                                       wordform=les  \n",
       "1         _                                                  _  \n",
       "2         _                                                  _  \n",
       "3         _                                                  _  \n",
       "4         _  CorrectForm=devenues|CorrectGender=Fem|Correct...  \n",
       "...     ...                                                ...  \n",
       "354562    _                                      SpaceAfter=No  \n",
       "354563    _                               ExtPos=ADV|Idiom=Yes  \n",
       "354564    _                                        InIdiom=Yes  \n",
       "354565    _                                      SpaceAfter=No  \n",
       "354566    _                                                  _  \n",
       "\n",
       "[354567 rows x 11 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>UPOS</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984778</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comprimant</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recyclant</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>évaporateurs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kriegsmarine</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delamarre</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42333 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "UPOS          ADJ       ADP       ADV      AUX  CCONJ       DET  INTJ  NOUN  \\\n",
       "de            0.0  0.984778  0.000042  0.00000    0.0  0.014002   0.0   0.0   \n",
       ",             0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       ".             0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "le            0.0  0.000000  0.000000  0.00000    0.0  0.979395   0.0   0.0   \n",
       "à             0.0  0.999450  0.000000  0.00033    0.0  0.000000   0.0   0.0   \n",
       "...           ...       ...       ...      ...    ...       ...   ...   ...   \n",
       "comprimant    0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "recyclant     0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "évaporateurs  0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   1.0   \n",
       "Kriegsmarine  0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "Delamarre     0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "\n",
       "UPOS          NUM      PRON  PROPN  PUNCT  SCONJ  SYM     VERB         X  \n",
       "de            0.0  0.000000    0.0    0.0    0.0  0.0  0.00000  0.001177  \n",
       ",             0.0  0.000000    0.0    1.0    0.0  0.0  0.00000  0.000000  \n",
       ".             0.0  0.000000    0.0    1.0    0.0  0.0  0.00000  0.000000  \n",
       "le            0.0  0.020444    0.0    0.0    0.0  0.0  0.00000  0.000161  \n",
       "à             0.0  0.000000    0.0    0.0    0.0  0.0  0.00011  0.000110  \n",
       "...           ...       ...    ...    ...    ...  ...      ...       ...  \n",
       "comprimant    0.0  0.000000    0.0    0.0    0.0  0.0  1.00000  0.000000  \n",
       "recyclant     0.0  0.000000    0.0    0.0    0.0  0.0  1.00000  0.000000  \n",
       "évaporateurs  0.0  0.000000    0.0    0.0    0.0  0.0  0.00000  0.000000  \n",
       "Kriegsmarine  0.0  0.000000    1.0    0.0    0.0  0.0  0.00000  0.000000  \n",
       "Delamarre     0.0  0.000000    1.0    0.0    0.0  0.0  0.00000  0.000000  \n",
       "\n",
       "[42333 rows x 16 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies = data['FORM'].value_counts()\n",
    "\n",
    "distribution = data.groupby('FORM')['UPOS'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "df=distribution.reindex(word_frequencies.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>UPOS</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984778</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comprimant</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recyclant</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>évaporateurs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kriegsmarine</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delamarre</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42333 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "UPOS          ADJ       ADP       ADV      AUX  CCONJ       DET  INTJ  NOUN  \\\n",
       "de            0.0  0.984778  0.000042  0.00000    0.0  0.014002   0.0   0.0   \n",
       ",             0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       ".             0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "le            0.0  0.000000  0.000000  0.00000    0.0  0.979395   0.0   0.0   \n",
       "à             0.0  0.999450  0.000000  0.00033    0.0  0.000000   0.0   0.0   \n",
       "...           ...       ...       ...      ...    ...       ...   ...   ...   \n",
       "comprimant    0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "recyclant     0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "évaporateurs  0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   1.0   \n",
       "Kriegsmarine  0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "Delamarre     0.0  0.000000  0.000000  0.00000    0.0  0.000000   0.0   0.0   \n",
       "\n",
       "UPOS          NUM      PRON  PROPN  PUNCT  SCONJ  SYM     VERB         X  \n",
       "de            0.0  0.000000    0.0    0.0    0.0  0.0  0.00000  0.001177  \n",
       ",             0.0  0.000000    0.0    1.0    0.0  0.0  0.00000  0.000000  \n",
       ".             0.0  0.000000    0.0    1.0    0.0  0.0  0.00000  0.000000  \n",
       "le            0.0  0.020444    0.0    0.0    0.0  0.0  0.00000  0.000161  \n",
       "à             0.0  0.000000    0.0    0.0    0.0  0.0  0.00011  0.000110  \n",
       "...           ...       ...    ...    ...    ...  ...      ...       ...  \n",
       "comprimant    0.0  0.000000    0.0    0.0    0.0  0.0  1.00000  0.000000  \n",
       "recyclant     0.0  0.000000    0.0    0.0    0.0  0.0  1.00000  0.000000  \n",
       "évaporateurs  0.0  0.000000    0.0    0.0    0.0  0.0  0.00000  0.000000  \n",
       "Kriegsmarine  0.0  0.000000    1.0    0.0    0.0  0.0  0.00000  0.000000  \n",
       "Delamarre     0.0  0.000000    1.0    0.0    0.0  0.0  0.00000  0.000000  \n",
       "\n",
       "[42333 rows x 16 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, group in distribution:\n",
    "    [word] = group['UPOS'].value_counts(normalize=True).to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
